{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully at models/model.pth\n"
     ]
    }
   ],
   "source": [
    "#this is to be removed ... this is just a dummy model to test the pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Define the model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 3)  # Assuming 3 classes: bored, attentive, confused\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dummy training loop (Replace with real data)\n",
    "for epoch in range(1):  # Run real training loop instead\n",
    "    optimizer.zero_grad()\n",
    "    dummy_input = torch.randn(1, 3, 224, 224)\n",
    "    output = model(dummy_input)\n",
    "    loss = loss_fn(output, torch.tensor([1]))  # Example target class\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"../models/model.pth\")\n",
    "print(\"✅ Model saved successfully at models/model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DAiSEEDataset Class\n",
    "\n",
    "This cell defines the full custom dataset class for DAiSEE. This definition is required for loading the saved dataset checkpoints and for training the model. Make sure to run this cell before loading any checkpoints.\n",
    "\n",
    "Below is the code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# Ensure the logger shows DEBUG messages\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class DAiSEEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Updated dataset class for DAiSEE that reads a CSV with four engagement metrics.\n",
    "    It precomputes the frame paths based on the ClipID and loads labels for \n",
    "    Boredom, Engagement, Confusion, and Frustration.\n",
    "    \n",
    "    If the ClipID does not contain a slash (i.e. it's just a number), the split is\n",
    "    inferred from the CSV file name. For example, for TrainLabels.csv, we assume the split is \"Train\".\n",
    "    \"\"\"\n",
    "    def __init__(self, root, csv_path, transform=None, seq_length=15):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Read the CSV file\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Pre-compute frame paths and labels with a progress bar\n",
    "        self.video_paths = []  # List to store sequences of frame paths\n",
    "        self.labels = []  # List to store labels\n",
    "        \n",
    "        logger.info(f\"Processing {len(self.data)} entries from {csv_path.name}\")\n",
    "        for idx, row in tqdm(self.data.iterrows(), total=len(self.data), desc=\"Loading dataset\"):\n",
    "            try:\n",
    "                clip_id = str(row['ClipID']).strip()\n",
    "                # Remove the .avi extension if present\n",
    "                if '.avi' in clip_id:\n",
    "                    clip_id = clip_id.replace('.avi', '')\n",
    "                parts = clip_id.split('/')\n",
    "                \n",
    "                # Determine the frame path based on the number of parts:\n",
    "                if len(parts) == 1:\n",
    "                    # If only one part exists, infer the split from the CSV filename.\n",
    "                    # For example, if csv_path is TrainLabels.csv, we deduce split = \"Train\".\n",
    "                    split_guess = csv_path.stem.replace(\"Labels\", \"\").strip()\n",
    "                    video_dir = self.root / split_guess / parts[0]\n",
    "                elif len(parts) == 2:\n",
    "                    video_dir = self.root / parts[0] / parts[1]\n",
    "                elif len(parts) >= 3:\n",
    "                    video_dir = self.root / parts[0] / parts[1] / parts[2]\n",
    "                else:\n",
    "                    logger.debug(f\"Skipping row {idx}: unexpected ClipID format: {clip_id}\")\n",
    "                    continue  # Skip rows that do not match the expected pattern\n",
    "\n",
    "                # Ensure the video directory exists\n",
    "                if not video_dir.exists():\n",
    "                    logger.debug(f\"Video directory does not exist: {video_dir}\")\n",
    "                    continue\n",
    "\n",
    "                # Collect frame paths\n",
    "                frames = list(video_dir.glob('frame_*.jpg'))\n",
    "                if len(frames) < self.seq_length:\n",
    "                    logger.debug(f\"Skipping video {clip_id}: not enough frames ({len(frames)} < {self.seq_length})\")\n",
    "                    continue\n",
    "\n",
    "                frames.sort()  # Ensure chronological order\n",
    "                self.video_paths.append(frames[:self.seq_length])  # Take the first `seq_length` frames\n",
    "                self.labels.append([\n",
    "                    float(row['Boredom']),\n",
    "                    float(row['Engagement']),\n",
    "                    float(row['Confusion']),\n",
    "                    float(str(row['Frustration ']).strip())\n",
    "                ])\n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Skipping row {idx} due to error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.video_paths)} valid video sequences\")\n",
    "        \n",
    "        if len(self.video_paths) == 0:\n",
    "            raise ValueError(f\"No valid video sequences found in {csv_path}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        frames_paths = self.video_paths[idx]\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        frame_tensors = []\n",
    "        for path in frames_paths:\n",
    "            img = Image.open(path)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            frame_tensors.append(img)\n",
    "        \n",
    "        sequence = torch.stack(frame_tensors)  # [seq_len, C, H, W]\n",
    "        return sequence, torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "# Register the dataset class for safe deserialization.\n",
    "torch.serialization.add_safe_globals({\"DAiSEEDataset\": DAiSEEDataset})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Datasets\n",
    "\n",
    "This cell loads the full datasets that were saved in 001_data.ipynb (e.g., `train_set.pth`, `val_set.pth`, and `test_set.pth`). Make sure to run this cell before training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the path where the dataset checkpoints were saved.\n",
    "FRAMES_ROOT = \"C:/Users/abhis/Downloads/Documents/Learner Engagement Project/data/DAiSEE/ExtractedFrames\"\n",
    "\n",
    "# Load the saved datasets using the full DAiSEEDataset class.\n",
    "train_dataset = torch.load(os.path.join(FRAMES_ROOT, \"train_set.pth\"), weights_only=False)\n",
    "val_dataset = torch.load(os.path.join(FRAMES_ROOT, \"val_set.pth\"), weights_only=False)\n",
    "test_dataset = torch.load(os.path.join(FRAMES_ROOT, \"test_set.pth\"), weights_only=False)\n",
    "\n",
    "print(\"✅ Datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "This cell creates DataLoaders for the training, validation, and testing datasets. These loaders will feed batches of data to your ML/DL models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4  # On Windows, consider using 0 if you encounter issues\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"✅ DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
