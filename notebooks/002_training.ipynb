{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Required Libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "# 1) Logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.FileHandler('training_classification.log')\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths \n",
    "DATASET_ROOT = Path(\"C:/Users/abhis/Downloads/Documents/Learner Engagement Project/data/DAiSEE/DataSet\").resolve()\n",
    "FRAMES_ROOT  = Path(\"C:/Users/abhis/Downloads/Documents/Learner Engagement Project/data/DAiSEE/ExtractedFrames\").resolve()\n",
    "\n",
    "#Helper function\n",
    "def get_csv_clip_id(video_stem: str) -> str:\n",
    "    \"\"\"\n",
    "    Maps old filenames to new ones if needed (like 110001 -> 202614).\n",
    "    \"\"\"\n",
    "    base = video_stem.strip()\n",
    "    if base.startswith(\"110001\"):\n",
    "        base = base.replace(\"110001\", \"202614\", 1)\n",
    "    return base\n",
    "\n",
    "#numercial sort key for frames\n",
    "import re\n",
    "def numeric_sort_key(path):\n",
    "    match = re.search(r'frame_(\\d+)\\.jpg', path.name)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DAiSEEDataset Class\n",
    "\n",
    "This class loads video sequences and pairs them with engagement metrics.\n",
    "\n",
    "- **Features**: Uses precomputed features for faster training.\n",
    "- **Error Handling**: Skips missing video directories and logs errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAiSEEDataset(Dataset):\n",
    "    def __init__(self, root, csv_path, transform=None, seq_len=15):\n",
    "        \"\"\"\n",
    "        seq_len=15 means we attempt to load up to 15 frames from each folder.\n",
    "        Adjust if you want fewer or more frames.\n",
    "        \"\"\"\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "        self.video_paths = []\n",
    "        self.labels = []\n",
    "        self.missing_videos = 0\n",
    "        self.total_videos = 0\n",
    "\n",
    "        df = pd.read_csv(csv_path, dtype=str)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        split = Path(csv_path).stem.replace(\"Labels\", \"\").strip()\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            self.total_videos += 1\n",
    "            try:\n",
    "                clip_id = row['ClipID'].strip()\n",
    "                filename = clip_id.split('/')[-1] if '/' in clip_id else clip_id\n",
    "                video_stem = filename.rsplit('.', 1)[0]\n",
    "                mapped_id = get_csv_clip_id(video_stem)\n",
    "\n",
    "                video_dir = self.root / split / mapped_id\n",
    "                if not video_dir.exists():\n",
    "                    self.missing_videos += 1\n",
    "                    continue\n",
    "                \n",
    "                frames = list(video_dir.glob('frame_*.jpg'))\n",
    "                if len(frames) < self.seq_len:\n",
    "                    self.missing_videos += 1\n",
    "                    continue\n",
    "\n",
    "                # We store path + 4-class integer labels\n",
    "                # Convert them from str to int for classification\n",
    "                boredom = int(row['Boredom'])\n",
    "                engage = int(row['Engagement'])\n",
    "                confuse = int(row['Confusion'])\n",
    "                frustrate = int(row['Frustration'])\n",
    "\n",
    "                self.video_paths.append(video_dir)\n",
    "                self.labels.append([boredom, engage, confuse, frustrate])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "\n",
    "        if not self.video_paths:\n",
    "            raise ValueError(\"No valid videos found for classification dataset.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_dir = self.video_paths[idx]\n",
    "        # labels: 4 separate integers (range [0..3])\n",
    "        label_list = self.labels[idx]\n",
    "\n",
    "        # numeric sort frames, then slice up to seq_len\n",
    "        frames_list = sorted(video_dir.glob('frame_*.jpg'), key=numeric_sort_key)[:self.seq_len]\n",
    "\n",
    "        frame_tensors = []\n",
    "        for path in frames_list:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = transforms.ToTensor()(img)\n",
    "            frame_tensors.append(img)\n",
    "\n",
    "        # shape: [seq_len, 3, H, W]\n",
    "        sequence = torch.stack(frame_tensors)\n",
    "        # shape: [4], each in [0..3]\n",
    "        label_tensor = torch.tensor(label_list, dtype=torch.long)\n",
    "\n",
    "        return sequence, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define the CNN-LSTM Model**\n",
    "\n",
    "**CNN-LSTM Model**:\n",
    "\n",
    "1.  ResNet50 extracts features from each frame.\n",
    "2.  LSTM processes temporal dependencies in sequences.\n",
    "3.  Outputs four-dimensional regression values (engagement metrics).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Classification(nn.Module):\n",
    "    def __init__(self, freeze_until='layer3'):\n",
    "        \"\"\"\n",
    "        We'll produce 16 logits total => 4 states × 4 classes each = 16.\n",
    "        Then we do a custom cross entropy for each dimension.\n",
    "        \"\"\"\n",
    "        super(CNN_LSTM_Classification, self).__init__()\n",
    "\n",
    "        # Use official weights to avoid deprecation warnings\n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Optionally freeze everything at first\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze from 'layer3' forward (this is partial unfreezing)\n",
    "        unfreeze = False\n",
    "        for name, child in self.resnet.named_children():\n",
    "            if name == freeze_until:\n",
    "                unfreeze = True\n",
    "            if unfreeze:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # We'll skip the final fc layer from resnet, we do LSTM + custom FC\n",
    "        # The output of resnet.avgpool is 2048-d\n",
    "        self.lstm_hidden = 512\n",
    "        self.lstm = nn.LSTM(2048, self.lstm_hidden, batch_first=True)\n",
    "        # 16 logits: 4 states × 4 classes each\n",
    "        self.fc = nn.Linear(self.lstm_hidden, 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, 3, H, W]\n",
    "        Returns: [batch_size, 16 logits]\n",
    "        We'll shape them to [batch_size, 4, 4] for multi cross-entropy.\n",
    "        \"\"\"\n",
    "        bsz, seq_len, c, h, w = x.shape\n",
    "        x = x.view(-1, c, h, w)  # flatten for ResNet forward\n",
    "\n",
    "        # forward pass up to avgpool\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)  # shape: [batch_size*seq_len, 2048, 1, 1]\n",
    "        x = x.view(x.size(0), -1)   # [batch_size*seq_len, 2048]\n",
    "\n",
    "        # reshape for LSTM\n",
    "        x = x.view(bsz, seq_len, -1)  # [bsz, seq_len, 2048]\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # take the last time step\n",
    "        last_step = lstm_out[:, -1, :]  # [bsz, hidden]\n",
    "        logits = self.fc(last_step)     # [bsz, 16]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-CrossEntropy for 4 states\n",
    "def multi_ce_loss(logits, labels):\n",
    "    \"\"\"\n",
    "    logits: [batch_size, 16]\n",
    "    labels: [batch_size, 4], each label in [0..3]\n",
    "    We'll reshape logits => [batch_size, 4, 4], then do CrossEntropy for each dimension.\n",
    "    Final loss is the average or sum of the 4 cross entropies.\n",
    "    \"\"\"\n",
    "    batch_size = logits.size(0)\n",
    "    # reshape => [bsz, 4 states, 4 classes]\n",
    "    logits_reshaped = logits.view(batch_size, 4, 4)  # e.g. [bsz, 4, 4]\n",
    "\n",
    "    # separate each dimension’s logits & label\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    # We'll compute CE for each dimension (boredom, engagement, etc.)\n",
    "    total_loss = 0.0\n",
    "    for d in range(4):\n",
    "        # logits for dimension d: [bsz, 4]\n",
    "        dim_logits = logits_reshaped[:, d, :]\n",
    "        # labels for dimension d: [bsz]\n",
    "        dim_labels = labels[:, d]\n",
    "        loss_d = ce(dim_logits, dim_labels)\n",
    "        total_loss += loss_d\n",
    "\n",
    "    # average or sum\n",
    "    return total_loss / 4.0  # average across the 4 states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Loaders**\n",
    "\n",
    "**Configures train, validation, and test loaders with optimal settings.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_dataloaders(batch_size=8, seq_len=15):\n",
    "    \"\"\"\n",
    "    We'll load up to 'seq_len' frames from each folder. \n",
    "    \"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    labels_path = DATASET_ROOT / \"Labels\"\n",
    "\n",
    "    train_ds = DAiSEEDataset(FRAMES_ROOT, labels_path / \"TrainLabels.csv\", transform=train_transform, seq_len=seq_len)\n",
    "    val_ds   = DAiSEEDataset(FRAMES_ROOT, labels_path / \"ValidationLabels.csv\", transform=val_transform, seq_len=seq_len)\n",
    "    test_ds  = DAiSEEDataset(FRAMES_ROOT, labels_path / \"TestLabels.csv\", transform=val_transform, seq_len=seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop with Optimizations\n",
    "\n",
    "- **Mixed Precision**: Uses FP16 for faster training.\n",
    "- **Checkpointing**: Saves the best model based on validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpointing\n",
    "def save_checkpoint(model, optimizer, epoch, best_val_loss, directory=\"models_class\"):\n",
    "    from pathlib import Path\n",
    "    import datetime\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_dir = Path(directory) / timestamp\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = save_dir / \"ResNet50_CNNLSTM_classification.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "def load_latest_checkpoint(model, optimizer, model_dir=\"models_class\", filename=\"ResNet50_CNNLSTM_classification.pth\",\n",
    "                           device=None):\n",
    "    from pathlib import Path\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_dir = Path(model_dir)\n",
    "    checkpoints = list(model_dir.rglob(filename))\n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "        return 0, float('inf')\n",
    "\n",
    "    latest_cpt = max(checkpoints, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading checkpoint from {latest_cpt}\")\n",
    "    cpoint = torch.load(latest_cpt, map_location=device)\n",
    "\n",
    "    model.load_state_dict(cpoint['model_state_dict'], strict=False)\n",
    "    optimizer.load_state_dict(cpoint['optimizer_state_dict'])\n",
    "    start_epoch = cpoint.get('epoch', 0) + 1\n",
    "    best_val_loss = cpoint.get('best_val_loss', float('inf'))\n",
    "\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "    return start_epoch, best_val_loss\n",
    "\n",
    "\n",
    "# Training Loop (Classification)\n",
    "def train_classification_model(model, train_loader, val_loader,\n",
    "                               epochs=10, lr=1e-4, early_stopping_patience=2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    model_save_dir = \"models_class\"\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=1)\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(enabled=True, device_type='cuda'):\n",
    "                logits = model(inputs)          # [batch, 16]\n",
    "                loss   = multi_ce_loss(logits, labels)  # custom multi-dim cross entropy\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} Val\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with autocast(enabled=True, device_type='cuda'):\n",
    "                    logits = model(inputs)\n",
    "                    loss = multi_ce_loss(logits, labels)\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        logger.info(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # checkpoint / early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            save_checkpoint(model, optimizer, epoch, best_val_loss, model_save_dir)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                logger.info(\"Early stopping triggered.\")\n",
    "                print(\"Early stopping triggered; training stopped.\")\n",
    "                break\n",
    "\n",
    "    print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation:** After training, use the evaluation function to compute additional metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(model, test_loader):\n",
    "    \"\"\"\n",
    "    We'll compute predicted classes for each dimension,\n",
    "    then compare them with ground truth to get classification_report\n",
    "    or custom accuracy for each dimension.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logits = model(inputs)  # [batch, 16]\n",
    "            # shape => [batch, 4, 4]\n",
    "            logits_reshaped = logits.view(-1, 4, 4)  # 4 dims × 4 classes\n",
    "\n",
    "            # For each dimension, pick argmax\n",
    "            # shape => [batch, 4]\n",
    "            dimension_preds = torch.argmax(logits_reshaped, dim=2)\n",
    "            all_preds.append(dimension_preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()   # shape [N, 4]\n",
    "    all_labels= torch.cat(all_labels, dim=0).numpy()  # shape [N, 4]\n",
    "\n",
    "    # We can do classification_report for each dimension\n",
    "    dimension_names = [\"Boredom\", \"Engagement\", \"Confusion\", \"Frustration\"]\n",
    "\n",
    "    for d in range(4):\n",
    "        print(f\"\\nDimension: {dimension_names[d]}\")\n",
    "        # We'll do classification report\n",
    "        print(classification_report(all_labels[:, d], all_preds[:, d],\n",
    "              labels=[0,1,2,3],\n",
    "              digits=3))\n",
    "\n",
    "    return all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Execution for CNN_LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|██████████| 304/304 [16:37<00:00,  3.28s/it]\n",
      "Epoch 1 Val: 100%|██████████| 90/90 [01:07<00:00,  1.33it/s]\n",
      "Epoch 1/15 | Train Loss: 0.8531 | Val Loss: 0.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to models_class\\20250213-140249\\ResNet50_CNNLSTM_classification.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: 100%|██████████| 304/304 [13:54<00:00,  2.74s/it]\n",
      "Epoch 2 Val: 100%|██████████| 90/90 [00:49<00:00,  1.83it/s]\n",
      "Epoch 2/15 | Train Loss: 0.8068 | Val Loss: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to models_class\\20250213-141733\\ResNet50_CNNLSTM_classification.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: 100%|██████████| 304/304 [13:16<00:00,  2.62s/it]\n",
      "Epoch 3 Val: 100%|██████████| 90/90 [00:57<00:00,  1.56it/s]\n",
      "Epoch 3/15 | Train Loss: 0.7904 | Val Loss: 0.9583\n",
      "Epoch 4 Train: 100%|██████████| 304/304 [15:53<00:00,  3.14s/it]\n",
      "Epoch 4 Val: 100%|██████████| 90/90 [00:57<00:00,  1.55it/s]\n",
      "Epoch 4/15 | Train Loss: 0.7716 | Val Loss: 0.9696\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered; training stopped.\n",
      "Training finished.\n",
      "Loading best checkpoint for evaluation: models_class\\20250213-141733\\ResNet50_CNNLSTM_classification.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 103/103 [10:16<00:00,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimension: Boredom\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.570     0.560     0.565       747\n",
      "           1      0.395     0.495     0.440       519\n",
      "           2      0.263     0.200     0.227       335\n",
      "           3      0.000     0.000     0.000        37\n",
      "\n",
      "    accuracy                          0.453      1638\n",
      "   macro avg      0.307     0.314     0.308      1638\n",
      "weighted avg      0.439     0.453     0.443      1638\n",
      "\n",
      "\n",
      "Dimension: Engagement\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         4\n",
      "           1      0.000     0.000     0.000        81\n",
      "           2      0.548     0.678     0.606       849\n",
      "           3      0.500     0.416     0.454       704\n",
      "\n",
      "    accuracy                          0.531      1638\n",
      "   macro avg      0.262     0.274     0.265      1638\n",
      "weighted avg      0.499     0.531     0.509      1638\n",
      "\n",
      "\n",
      "Dimension: Confusion\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.704     0.963     0.813      1135\n",
      "           1      0.390     0.087     0.142       368\n",
      "           2      0.667     0.017     0.034       116\n",
      "           3      0.000     0.000     0.000        19\n",
      "\n",
      "    accuracy                          0.688      1638\n",
      "   macro avg      0.440     0.267     0.247      1638\n",
      "weighted avg      0.623     0.688     0.598      1638\n",
      "\n",
      "\n",
      "Dimension: Frustration\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.781     1.000     0.877      1279\n",
      "           1      0.000     0.000     0.000       280\n",
      "           2      0.000     0.000     0.000        56\n",
      "           3      0.000     0.000     0.000        23\n",
      "\n",
      "    accuracy                          0.781      1638\n",
      "   macro avg      0.195     0.250     0.219      1638\n",
      "weighted avg      0.610     0.781     0.685      1638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\abhis\\Downloads\\Documents\\Learner Engagement Project\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Get Dataloaders\n",
    "train_loader, val_loader, test_loader = get_classification_dataloaders(\n",
    "    batch_size=16,  # or 16 if your GPU can handle it\n",
    "    seq_len=15     # bigger sequence length for more temporal data\n",
    ")\n",
    "\n",
    "# 2. Instantiate Model\n",
    "# e.g. freeze_until='layer3' or 'layer2' or 'layer1' depending on how much you want to fine-tune\n",
    "model = CNN_LSTM_Classification(freeze_until='layer2')\n",
    "\n",
    "# 3. Train\n",
    "train_classification_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=15,\n",
    "    lr=5e-5,              # adjust as needed\n",
    "    early_stopping_patience=2\n",
    ")\n",
    "\n",
    "# 4. Evaluate Best Checkpoint\n",
    "# Re-instantiate the same architecture\n",
    "model_eval = CNN_LSTM_Classification(freeze_until='layer3')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_eval.to(device)\n",
    "\n",
    "# load the best checkpoint\n",
    "from pathlib import Path\n",
    "model_dir = Path(\"models_class\")\n",
    "cpts = list(model_dir.rglob(\"ResNet50_CNNLSTM_classification.pth\"))\n",
    "if cpts:\n",
    "    best_ckpt = max(cpts, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading best checkpoint for evaluation: {best_ckpt}\")\n",
    "    cpoint = torch.load(best_ckpt, map_location=device)\n",
    "    model_eval.load_state_dict(cpoint['model_state_dict'], strict=False)\n",
    "\n",
    "# classification evaluation\n",
    "all_preds, all_labels = evaluate_classification(model_eval, test_loader)\n",
    "# you get a classification_report per dimension\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
