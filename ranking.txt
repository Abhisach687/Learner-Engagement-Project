
Fusion Approach in app.py
In app.py, a selective fusion approach is used:

Two base models are employed:

ProEnsembleDistillation: A temporal neural model that processes frame sequences
XGBoost with HOG features: A traditional ML approach with handcrafted features
The fusion strategy uses:

Confidence thresholding: If ProEnsemble confidence > 0.35, use that prediction directly
Model selection by emotion: Use different models for different emotions
For Engagement: Use ProEnsembleDistillation
For Boredom, Confusion, Frustration: Use XGBoost
Temporal smoothing: Applying weighted smoothing to predictions over time
This is a hybrid selective fusion that leverages the strengths of each model for specific emotions.




1. XGBOOST_HOG.ipynb metrics

==================================================
Processing Engagement
==================================================

Evaluating model for Engagement...
Original distribution: [0.00466418 0.01026119 0.55317164 0.43190299]
True distribution: [0.00932836 0.03731343 0.48507463 0.46828358]
Predictions eligible for modification: 294/1072 (27.4%)
Converted 5 predictions to class 0 for minimum representation
Converted 29 predictions to class 1 for minimum representation
New distribution: [0.00932836 0.03731343 0.53264925 0.42070896]
Engagement validation accuracy: 0.4925

Classification Report:
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000        10
           1     0.0500    0.0500    0.0500        40
           2     0.5166    0.5673    0.5408       520
           3     0.5122    0.4602    0.4848       502

    accuracy                         0.4925      1072
   macro avg     0.2697    0.2694    0.2689      1072
weighted avg     0.4923    0.4925    0.4912      1072

Confusion Matrix:
[[  0   0   3   7]
 [  0   2  28  10]
 [  5  17 295 203]
 [  5  21 245 231]]

==================================================
Processing Boredom
==================================================

Evaluating model for Boredom...
Original distribution: [0.54850746 0.29104478 0.14925373 0.01119403]
True distribution: [0.4738806  0.30037313 0.19776119 0.02798507]
Predictions eligible for modification: 359/1072 (33.5%)
Converted 20 predictions from class 0 to class 1
Converted 43 predictions from class 0 to class 2
Converted 11 predictions from class 0 to class 3
New distribution: [0.47947761 0.30970149 0.18936567 0.02145522]
Boredom validation accuracy: 0.4580

Classification Report:
              precision    recall  f1-score   support

           0     0.5837    0.5906    0.5871       508
           1     0.3705    0.3820    0.3761       322
           2     0.3202    0.3066    0.3133       212
           3     0.1304    0.1000    0.1132        30

    accuracy                         0.4580      1072
   macro avg     0.3512    0.3448    0.3474      1072
weighted avg     0.4548    0.4580    0.4563      1072

Confusion Matrix:
[[300 130  69   9]
 [130 123  61   8]
 [ 74  70  65   3]
 [ 10   9   8   3]]

==================================================
Processing Confusion
==================================================

Evaluating model for Confusion...
Original distribution: [0.8386194  0.12686567 0.02985075 0.00466418]
True distribution: [0.67630597 0.23041045 0.08395522 0.00932836]
Predictions eligible for modification: 256/1072 (23.9%)
New distribution: [0.8386194  0.12686567 0.02985075 0.00466418]
Confusion validation accuracy: 0.6362

Classification Report:
              precision    recall  f1-score   support

           0     0.7019    0.8703    0.7771       725
           1     0.3529    0.1943    0.2507       247
           2     0.0938    0.0333    0.0492        90
           3     0.0000    0.0000    0.0000        10

    accuracy                         0.6362      1072
   macro avg     0.2871    0.2745    0.2692      1072
weighted avg     0.5639    0.6362    0.5874      1072

Confusion Matrix:
[[631  68  22   4]
 [194  48   5   0]
 [ 68  18   3   1]
 [  6   2   2   0]]

==================================================
Processing Frustration
==================================================

Evaluating model for Frustration...
Original distribution: [0.93376866 0.05503731 0.00839552 0.00279851]
True distribution: [0.7733209  0.18097015 0.03264925 0.0130597 ]
Predictions eligible for modification: 122/1072 (11.4%)
Converted 48 predictions from class 0 to class 1
New distribution: [0.88899254 0.09981343 0.00839552 0.00279851]
Frustration validation accuracy: 0.7239

Classification Report:
              precision    recall  f1-score   support

           0     0.7859    0.9035    0.8406       829
           1     0.2523    0.1392    0.1794       194
           2     0.0000    0.0000    0.0000        35
           3     0.0000    0.0000    0.0000        14

    accuracy                         0.7239      1072
   macro avg     0.2596    0.2607    0.2550      1072
weighted avg     0.6534    0.7239    0.6825      1072

Confusion Matrix:
[[749  73   4   3]
 [163  27   4   0]
 [ 30   5   0   0]
 [ 11   2   1   0]]

--- Performance Summary ---
Engagement: 0.4925
Boredom: 0.4580
Confusion: 0.6362
Frustration: 0.7239

--- Evaluation Complete ---

2. MobileNetV2-TCN.ipynb


--- Starting Evaluation ---
Loaded precomputed frames for 1638 videos from cache.
Evaluating: 100%|██████████| 205/205 [04:34<00:00,  1.34s/it]

Evaluating model for Engagement...
Engagement validation accuracy: 0.4133

Classification Report:
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000         4
           1     0.0750    0.0741    0.0745        81
           2     0.4668    0.3557    0.4037       849
           3     0.4068    0.5241    0.4581       704

    accuracy                         0.4133      1638
   macro avg     0.2372    0.2385    0.2341      1638
weighted avg     0.4205    0.4133    0.4098      1638

Confusion Matrix:
[[  0   0   3   1]
 [  0   6  33  42]
 [  4  48 302 495]
 [  0  26 309 369]]

Evaluating model for Boredom...
Boredom validation accuracy: 0.3877

Classification Report:
              precision    recall  f1-score   support

           0     0.4987    0.4993    0.4990       747
           1     0.3487    0.3487    0.3487       519
           2     0.2395    0.2388    0.2392       335
           3     0.0270    0.0270    0.0270        37

    accuracy                         0.3877      1638
   macro avg     0.2785    0.2785    0.2785      1638
weighted avg     0.3875    0.3877    0.3876      1638

Confusion Matrix:
[[373 209 148  17]
 [229 181  95  14]
 [137 113  80   5]
 [  9  16  11   1]]


Evaluating model for Confusion...
Confusion validation accuracy: 0.5385

Classification Report:
              precision    recall  f1-score   support

           0     0.6960    0.6960    0.6960      1135
           1     0.2337    0.2337    0.2337       368
           2     0.0517    0.0517    0.0517       116
           3     0.0000    0.0000    0.0000        19

    accuracy                         0.5385      1638
   macro avg     0.2454    0.2454    0.2454      1638
weighted avg     0.5385    0.5385    0.5385      1638

Confusion Matrix:
[[790 252  80  13]
 [247  86  30   5]
 [ 82  27   6   1]
 [ 16   3   0   0]]


Evaluating model for Frustration...
Frustration validation accuracy: 0.6227

Classification Report:
              precision    recall  f1-score   support

           0     0.7670    0.7670    0.7670      1279
           1     0.1393    0.1393    0.1393       280
           2     0.0000    0.0000    0.0000        56
           3     0.0000    0.0000    0.0000        23

    accuracy                         0.6227      1638
   macro avg     0.2266    0.2266    0.2266      1638
weighted avg     0.6227    0.6227    0.6227      1638

Confusion Matrix:
[[981 233  46  19]
 [229  39   8   4]
 [ 48   7   0   1]
 [ 21   1   1   0]]



3. MobileNetV2-TCN-Balance.ipynb

--- Starting Evaluation ---
Loading single model from: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_balance_0.pth
Model loaded successfully
Loaded precomputed frames for 1638 videos from cache.
Evaluating: 100%|██████████| 410/410 [05:08<00:00,  1.33it/s]

Evaluating model for Engagement...
Engagement validation accuracy: 0.4286
Engagement validation F1-score: 0.1951

Classification Report:
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.19      0.16      0.17        81
           2       0.00      0.00      0.00       849
           3       0.44      0.98      0.61       704

    accuracy                           0.43      1638
   macro avg       0.16      0.28      0.20      1638
weighted avg       0.20      0.43      0.27      1638

Confusion Matrix:
[[  0   1   0   3]
 [  0  13   0  68]
 [  0  39   0 810]
 [  0  15   0 689]]


Evaluating model for Boredom...
Boredom validation accuracy: 0.3242
Boredom validation F1-score: 0.2939

Classification Report:
              precision    recall  f1-score   support

           0       0.63      0.15      0.24       747
           1       0.32      0.56      0.41       519
           2       0.23      0.35      0.28       335
           3       0.23      0.27      0.25        37

    accuracy                           0.32      1638
   macro avg       0.35      0.33      0.29      1638
weighted avg       0.44      0.32      0.30      1638

Confusion Matrix:
[[112 431 201   3]
 [ 40 293 172  14]
 [ 25 177 116  17]
 [  2  16   9  10]]

Evaluating model for Confusion...
Confusion validation accuracy: 0.3932
Confusion validation F1-score: 0.2270

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.46      0.55      1135
           1       0.19      0.23      0.20       368
           2       0.09      0.37      0.15       116
           3       0.00      0.00      0.00        19

    accuracy                           0.39      1638
   macro avg       0.25      0.26      0.23      1638
weighted avg       0.54      0.39      0.44      1638

Confusion Matrix:
[[518 337 280   0]
 [160  83 125   0]
 [ 50  23  43   0]
 [  9   2   8   0]]
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))



Evaluating model for Frustration...
Frustration validation accuracy: 0.6990
Frustration validation F1-score: 0.2450

Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.88      0.84      1279
           1       0.00      0.00      0.00       280
           2       0.08      0.38      0.14        56
           3       0.00      0.00      0.00        23

    accuracy                           0.70      1638
   macro avg       0.22      0.31      0.25      1638
weighted avg       0.64      0.70      0.66      1638

Confusion Matrix:
[[1124    0  155    0]
 [ 215    0   65    0]
 [  35    0   21    0]
 [  13    0   10    0]]
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))


3. EfficientNetV2L_TCN_CBAM.ipynb

INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Evaluating: 100%|██████████| 205/205 [00:03<00:00, 65.19it/s]
Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.12      0.25      0.17         4
           1       0.07      0.07      0.07        81
           2       0.57      0.56      0.57       849
           3       0.49      0.50      0.50       704

    accuracy                           0.51      1638
   macro avg       0.32      0.35      0.33      1638
weighted avg       0.51      0.51      0.51      1638

Confusion Matrix:
[[  1   0   1   2]
 [  3   6  34  38]
 [  2  47 479 321]
 [  2  28 321 353]]


Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.50      0.50      0.50       747
           1       0.38      0.38      0.38       519
           2       0.17      0.16      0.17       335
           3       0.06      0.05      0.06        37

    accuracy                           0.38      1638
   macro avg       0.28      0.28      0.28      1638
weighted avg       0.38      0.38      0.38      1638

Confusion Matrix:
[[376 179 181  11]
 [224 197  87  11]
 [146 126  55   8]
 [  9  22   4   2]]


Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65      1135
           1       0.20      0.20      0.20       368
           2       0.01      0.01      0.01       116
           3       0.00      0.00      0.00        19

    accuracy                           0.50      1638
   macro avg       0.22      0.21      0.22      1638
weighted avg       0.50      0.50      0.50      1638

Confusion Matrix:
[[739 277 102  17]
 [272  73  19   4]
 [105  10   1   0]
 [ 19   0   0   0]]


Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.75      0.75      0.75      1279
           1       0.11      0.11      0.11       280
           2       0.02      0.02      0.02        56
           3       0.00      0.00      0.00        23

    accuracy                           0.61      1638
   macro avg       0.22      0.22      0.22      1638
weighted avg       0.61      0.61      0.61      1638

Confusion Matrix:
[[960 241  52  26]
 [246  30   4   0]
 [ 49   6   1   0]
 [ 22   1   0   0]]



4. EffNet_TCN_exp2.ipynb


Evaluating: 100%|██████████| 103/103 [00:04<00:00, 24.89it/s]

Post-processing Engagement...

Post-processing Boredom...

Post-processing Confusion...

Post-processing Frustration...

Evaluating Engagement...

Engagement Classification Report:
              precision    recall  f1-score   support

           0      0.004     0.750     0.008         4
           1      0.050     0.531     0.091        81
           2      0.500     0.005     0.009       849
           3      0.286     0.014     0.027       704

    accuracy                          0.037      1638
   macro avg      0.210     0.325     0.034      1638
weighted avg      0.384     0.037     0.021      1638


Evaluating Boredom...

Boredom Classification Report:
              precision    recall  f1-score   support

           0      0.250     0.003     0.005       747
           1      0.324     0.324     0.324       519
           2      0.147     0.146     0.146       335
           3      0.019     0.405     0.037        37

    accuracy                          0.143      1638
   macro avg      0.185     0.220     0.128      1638
weighted avg      0.247     0.143     0.136      1638

Saved confusion matrix to: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\Boredom_confusion_matrix.png


Evaluating Confusion...

Confusion Classification Report:
              precision    recall  f1-score   support

           0      0.692     0.692     0.692      1135
           1      0.215     0.215     0.215       368
           2      0.078     0.078     0.078       116
           3      0.000     0.000     0.000        19

    accuracy                          0.533      1638
   macro avg      0.246     0.246     0.246      1638
weighted avg      0.533     0.533     0.533      1638

Saved confusion matrix to: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\Confusion_confusion_matrix.pngEvaluating Frustration...

Frustration Classification Report:
              precision    recall  f1-score   support

           0      0.773     0.773     0.773      1279
           1      0.175     0.175     0.175       280
           2      0.055     0.054     0.054        56
           3      0.000     0.000     0.000        23

    accuracy                          0.636      1638
   macro avg      0.251     0.250     0.251      1638
weighted avg      0.636     0.636     0.636      1638

Saved confusion matrix to: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\Frustration_confusion_matrix.png

=== Overall Results ===
Average Accuracy: 0.3370
Average Macro F1: 0.1647
Engagement: Acc=0.0366, F1=0.0340
Boredom: Acc=0.1429, F1=0.1281
Confusion: Acc=0.5330, F1=0.2460
Frustration: Acc=0.6355, F1=0.2506

Training and evaluation complete!

5. EfficientNetV2L_RefinedCrossAttn_CBAM.ipynb

Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.00      0.00      0.00        81
           2       0.53      0.49      0.51       849
           3       0.45      0.54      0.49       704

    accuracy                           0.49      1638
   macro avg       0.25      0.26      0.25      1638
weighted avg       0.47      0.49      0.48      1638

Confusion Matrix:
[[  0   0   2   2]
 [  0   0  40  41]
 [  0   0 418 431]
 [  0   0 322 382]]


Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.43      0.43      0.43       747
           1       0.30      0.30      0.30       519
           2       0.20      0.20      0.20       335
           3       0.03      0.03      0.03        37

    accuracy                           0.33      1638
   macro avg       0.24      0.24      0.24      1638
weighted avg       0.33      0.33      0.33      1638

Confusion Matrix:
[[322 256 157  12]
 [249 157 102  11]
 [163  98  66   8]
 [ 16  13   7   1]]

Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.70      0.72      0.71      1135
           1       0.27      0.27      0.27       368
           2       0.04      0.03      0.04       116
           3       0.00      0.00      0.00        19

    accuracy                           0.56      1638
   macro avg       0.25      0.25      0.25      1638
weighted avg       0.55      0.56      0.55      1638

Confusion Matrix:
[[814 234  74  13]
 [248  98  20   2]
 [ 86  25   4   1]
 [ 16   3   0   0]]

Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.78      0.83      0.81      1279
           1       0.21      0.16      0.18       280
           2       0.02      0.02      0.02        56
           3       0.00      0.00      0.00        23

    accuracy                           0.68      1638
   macro avg       0.25      0.25      0.25      1638
weighted avg       0.65      0.68      0.66      1638

Confusion Matrix:
[[1066  159   43   11]
 [ 226   45    5    4]
 [  48    6    1    1]
 [  20    3    0    0]]


6. EfficientNetV2L_BiLSTM_SpatialCBAM_ProgRes_AdamW.ipynb

Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.07      0.07      0.07        81
           2       0.53      0.53      0.53       849
           3       0.46      0.46      0.46       704

    accuracy                           0.48      1638
   macro avg       0.27      0.27      0.27      1638
weighted avg       0.48      0.48      0.48      1638

Confusion Matrix:
[[  0   0   3   1]
 [  0   6  37  38]
 [  0  51 450 348]
 [  0  24 355 325]]

Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.71      0.72      0.71      1135
           1       0.31      0.32      0.31       368
           2       0.08      0.07      0.07       116
           3       0.00      0.00      0.00        19

    accuracy                           0.57      1638
   macro avg       0.28      0.28      0.28      1638
weighted avg       0.57      0.57      0.57      1638

Confusion Matrix:
[[813 234  73  15]
 [234 117  16   1]
 [ 87  21   8   0]
 [ 14   4   1   0]]

Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.49      0.54      0.51       747
           1       0.34      0.30      0.32       519
           2       0.16      0.16      0.16       335
           3       0.03      0.03      0.03        37

    accuracy                           0.37      1638
   macro avg       0.26      0.26      0.26      1638
weighted avg       0.37      0.37      0.37      1638

Confusion Matrix:
[[404 177 153  13]
 [241 156 111  11]
 [168 107  53   7]
 [ 11  16   9   1]]



Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.78      0.82      0.80      1279
           1       0.17      0.13      0.15       280
           2       0.06      0.05      0.06        56
           3       0.00      0.00      0.00        23

    accuracy                           0.66      1638
   macro avg       0.25      0.25      0.25      1638
weighted avg       0.64      0.66      0.65      1638

Confusion Matrix:
[[1048  175   41   15]
 [ 238   37    4    1]
 [  45    8    3    0]
 [  19    3    1    0]]


7. EfficientNetV2L_BiLSTM_CrossAttn_CBAM_NEXT.ipynb

Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.01      0.01      0.01        81
           2       0.54      0.48      0.51       849
           3       0.47      0.54      0.50       704

    accuracy                           0.48      1638
   macro avg       0.26      0.26      0.26      1638
weighted avg       0.49      0.48      0.48      1638

Confusion Matrix:
[[  0   1   1   2]
 [  0   1  46  34]
 [  0  51 410 388]
 [  0  28 297 379]]

Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.47      0.69      0.56       747
           1       0.26      0.11      0.15       519
           2       0.27      0.24      0.25       335
           3       0.00      0.00      0.00        37

    accuracy                           0.40      1638
   macro avg       0.25      0.26      0.24      1638
weighted avg       0.35      0.40      0.35      1638

Confusion Matrix:
[[515  97 120  15]
 [368  55  84  12]
 [202  49  79   5]
 [ 16   9  12   0]]

Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.71      0.72      0.72      1135
           1       0.30      0.30      0.30       368
           2       0.05      0.04      0.05       116
           3       0.00      0.00      0.00        19

    accuracy                           0.57      1638
   macro avg       0.26      0.27      0.27      1638
weighted avg       0.56      0.57      0.57      1638

Confusion Matrix:
[[818 232  73  12]
 [234 111  20   3]
 [ 84  26   5   1]
 [ 12   7   0   0]]

Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.79      0.80      0.80      1279
           1       0.19      0.19      0.19       280
           2       0.02      0.02      0.02        56
           3       0.06      0.04      0.05        23

    accuracy                           0.66      1638
   macro avg       0.27      0.26      0.27      1638
weighted avg       0.65      0.66      0.66      1638

Confusion Matrix:
[[1027  199   40   13]
 [ 217   54    7    2]
 [  38   17    1    0]
 [  13    8    1    1]]

8. EfficientNetV2L_BiLSTM_CrossAttn_CBAM_full.ipynb

Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.02      0.02      0.02        81
           2       0.51      0.51      0.51       849
           3       0.42      0.43      0.43       704

    accuracy                           0.45      1638
   macro avg       0.24      0.24      0.24      1638
weighted avg       0.45      0.45      0.45      1638

Confusion Matrix:
[[  0   0   1   3]
 [  0   2  41  38]
 [  0  45 434 370]
 [  0  34 369 301]]


Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.44      0.45      0.45       747
           1       0.34      0.34      0.34       519
           2       0.16      0.16      0.16       335
           3       0.00      0.00      0.00        37

    accuracy                           0.34      1638
   macro avg       0.24      0.24      0.24      1638
weighted avg       0.34      0.34      0.34      1638

Confusion Matrix:
[[335 233 165  14]
 [228 177 102  12]
 [173 104  52   6]
 [ 19  10   8   0]]

Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70      1135
           1       0.23      0.23      0.23       368
           2       0.04      0.03      0.04       116
           3       0.00      0.00      0.00        19

    accuracy                           0.54      1638
   macro avg       0.24      0.24      0.24      1638
weighted avg       0.54      0.54      0.54      1638

Confusion Matrix:
[[800 258  69   8]
 [253  86  24   5]
 [ 85  24   4   3]
 [ 10   8   1   0]]


Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.80      0.81      0.80      1279
           1       0.19      0.19      0.19       280
           2       0.02      0.02      0.02        56
           3       0.12      0.09      0.10        23

    accuracy                           0.66      1638
   macro avg       0.28      0.27      0.28      1638
weighted avg       0.66      0.66      0.66      1638

Confusion Matrix:
[[1030  198   40   11]
 [ 216   53    8    3]
 [  34   21    1    0]
 [  15    6    0    2]]


9. EfficientNetV2L_BiLSTM_CrossAttn_CBAM_ENSEMBLE.ipynb

--- Starting Evaluation ---
Loading model from: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_eff_v2l__bilstm_crossattn_cbam_checkpoint.pth
Detected LSTM hidden size: 512
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_l.in21k_ft_in1k)
INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.

--- Evaluating Single Model with TTA ---
Evaluating: 100%|██████████| 819/819 [1:59:52<00:00,  8.78s/it]  

  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
c:\Users\abhis\Downloads\Documents\Learner Engagement Project\venv\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Classification report for Engagement:
              precision    recall  f1-score   support

           0      0.000     0.000     0.000         4
           1      0.025     0.025     0.025        81
           2      0.505     0.503     0.504       849
           3      0.426     0.430     0.428       704

    accuracy                          0.447      1638
   macro avg      0.239     0.240     0.239      1638
weighted avg      0.446     0.447     0.446      1638

Confusion Matrix:
[[  0   0   2   2]
 [  0   2  43  36]
 [  0  51 427 371]
 [  0  28 373 303]]

Classification report for Boredom:
              precision    recall  f1-score   support

           0      0.453     0.458     0.455       747
           1      0.347     0.351     0.349       519
           2      0.165     0.161     0.163       335
           3      0.031     0.027     0.029        37

    accuracy                          0.353      1638
   macro avg      0.249     0.249     0.249      1638
weighted avg      0.351     0.353     0.352      1638

Confusion Matrix:
[[342 232 158  15]
 [221 182 104  12]
 [177 100  54   4]
 [ 15  10  11   1]]

Classification report for Confusion:
              precision    recall  f1-score   support

           0      0.694     0.704     0.699      1135
           1      0.233     0.236     0.235       368
           2      0.071     0.060     0.065       116
           3      0.000     0.000     0.000        19

    accuracy                          0.545      1638
   macro avg      0.250     0.250     0.250      1638
weighted avg      0.538     0.545     0.542      1638

Confusion Matrix:
[[799 253  73  10]
 [259  87  17   5]
 [ 81  27   7   1]
 [ 12   6   1   0]]

Classification report for Frustration:
              precision    recall  f1-score   support

           0      0.780     0.794     0.787      1279
           1      0.170     0.164     0.167       280
           2      0.000     0.000     0.000        56
           3      0.000     0.000     0.000        23

    accuracy                          0.648      1638
   macro avg      0.237     0.239     0.238      1638
weighted avg      0.638     0.648     0.643      1638

Confusion Matrix:
[[1015  208   43   13]
 [ 225   46    6    3]
 [  43   13    0    0]
 [  19    4    0    0]]

9.1 Ensemble 

--- Efficient Ensemble Evaluation ---
Using 4 models in ensemble

--- Efficient Ensemble Evaluation (40% of data at 224×224) ---
Using all 4 checkpoints for ensemble evaluation
Loading model 1/4: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_eff_v2l__bilstm_crossattn_cbam_checkpoint.pth
  Detected LSTM hidden size: 512
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_l.in21k_ft_in1k)
INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Loading model 2/4: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\seed_42_ensemble_model_checkpoint.pth
  Detected LSTM hidden size: 512
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_l.in21k_ft_in1k)
INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Loading model 3/4: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\seed_101_ensemble_model_checkpoint.pth
  Detected LSTM hidden size: 256
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_l.in21k_ft_in1k)
INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Loading model 4/4: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\seed_2023_ensemble_model_checkpoint.pth
  Detected LSTM hidden size: 256
INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/tf_efficientnetv2_l.in21k_ft_in1k)
INFO:timm.models._hub:[timm/tf_efficientnetv2_l.in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
Evaluating on 327 of 819 batches
Ensemble Evaluation:  40%|███▉      | 327/819 [1:01:20<1:32:16, 11.25s/it]

Ensemble classification report for Engagement:
              precision    recall  f1-score   support

           0      0.000     0.000     0.000         2
           1      0.156     0.152     0.154        33
           2      0.583     0.532     0.556       370
           3      0.391     0.446     0.417       249

    accuracy                          0.479       654
   macro avg      0.282     0.282     0.282       654
weighted avg      0.486     0.479     0.481       654

Confusion Matrix:
[[  0   0   0   2]
 [  0   5  14  14]
 [  0  16 197 157]
 [  0  11 127 111]]

Ensemble classification report for Boredom:
              precision    recall  f1-score   support

           0      0.433     0.482     0.456       276
           1      0.255     0.298     0.275       178
           2      0.333     0.232     0.274       181
           3      0.000     0.000     0.000        19

    accuracy                          0.349       654
   macro avg      0.255     0.253     0.251       654
weighted avg      0.344     0.349     0.343       654

Confusion Matrix:
[[133  92  45   6]
 [ 89  53  34   2]
 [ 76  58  42   5]
 [  9   5   5   0]]

Ensemble classification report for Confusion:
              precision    recall  f1-score   support

           0      0.769     0.733     0.751       505
           1      0.180     0.209     0.193       110
           2      0.000     0.000     0.000        35
           3      0.000     0.000     0.000         4

    accuracy                          0.601       654
   macro avg      0.237     0.235     0.236       654
weighted avg      0.624     0.601     0.612       654

Confusion Matrix:
[[370 101  28   6]
 [ 76  23  11   0]
 [ 31   4   0   0]
 [  4   0   0   0]]

Ensemble classification report for Frustration:
              precision    recall  f1-score   support

           0      0.829     0.804     0.816       542
           1      0.098     0.108     0.103        93
           2      0.000     0.000     0.000        12
           3      0.000     0.000     0.000         7

    accuracy                          0.682       654
   macro avg      0.232     0.228     0.230       654
weighted avg      0.701     0.682     0.691       654

Confusion Matrix:
[[436  86  16   4]
 [ 77  10   4   2]
 [  6   6   0   0]
 [  7   0   0   0]]


10. EfficientNetB3_LSTM.ipynb

Precomputing frames:   0%|          | 0/5358 [00:00<?, ?it/s]Precomputing frames: 100%|██████████| 5358/5358 [00:17<00:00, 298.42it/s]
Precomputation: Skipped 507 videos out of 5358.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_TrainLabels_frame_30.pkl
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_TrainLabels_frame_30
Precomputing frames: 100%|██████████| 1429/1429 [00:04<00:00, 311.75it/s]
Precomputation: Skipped 0 videos out of 1429.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_ValidationLabels_frame_30.pkl
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_ValidationLabels_frame_30
Precomputing frames: 100%|██████████| 1784/1784 [00:05<00:00, 328.49it/s]
Precomputation: Skipped 146 videos out of 1784.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_TestLabels_frame_30.pkl
[I 2025-03-25 05:09:15,150] Using an existing study with name 'efficientnetb3_lstm_study' instead of creating a new one.
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_TestLabels_frame_30
Optuna tuning complete. Total successful trials: 10
Best trial parameters: {'num_frames': 30, 'batch_size': 4, 'lr': 0.00046142041717863776, 'epochs': 3, 'hidden_size': 64, 'num_lstm_layers': 2}

--- Skipping Final Training (Checkpoint Exists) ---
Using model from: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_eff_checkpoint.pth
Evaluating: 100%|██████████| 410/410 [00:04<00:00, 100.94it/s]
Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.04      0.04      0.04        81
           2       0.48      0.41      0.44       849
           3       0.39      0.45      0.42       704

    accuracy                           0.41      1638
   macro avg       0.23      0.22      0.22      1638
weighted avg       0.42      0.41      0.41      1638

Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.50      0.71      0.58       747
           1       0.48      0.19      0.27       519
           2       0.21      0.20      0.21       335
           3       0.05      0.05      0.05        37

    accuracy                           0.43      1638
   macro avg       0.31      0.29      0.28      1638
weighted avg       0.42      0.43      0.40      1638

Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.74      0.76      0.75      1135
           1       0.23      0.20      0.22       368
           2       0.12      0.12      0.12       116
           3       0.00      0.00      0.00        19

    accuracy                           0.58      1638
   macro avg       0.27      0.27      0.27      1638
weighted avg       0.57      0.58      0.58      1638

Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.83      0.84      0.83      1279
           1       0.29      0.29      0.29       280
           2       0.10      0.09      0.10        56
           3       0.00      0.00      0.00        23

    accuracy                           0.71      1638
   macro avg       0.30      0.30      0.30      1638
weighted avg       0.70      0.71      0.70      1638


--- Evaluation Complete ---


11. EfficientNetB3_LSTM_full.ipynb

Precomputing frames:   0%|          | 0/5358 [00:00<?, ?it/s]Precomputing frames: 100%|██████████| 5358/5358 [00:17<00:00, 305.59it/s] 
Precomputation: Skipped 507 videos out of 5358.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_TrainLabels_frame_30.pkl
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_TrainLabels_frame_30
Precomputing frames: 100%|██████████| 1429/1429 [00:05<00:00, 284.48it/s]
Precomputation: Skipped 0 videos out of 1429.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_ValidationLabels_frame_30.pkl
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_ValidationLabels_frame_30
Precomputing frames: 100%|██████████| 1784/1784 [00:05<00:00, 299.24it/s]
Precomputation: Skipped 146 videos out of 1784.
Precomputed results saved to C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\precomputed_TestLabels_frame_30.pkl
[I 2025-04-02 11:17:06,308] Using an existing study with name 'efficientnetb3_lstm_study' instead of creating a new one.
LMDB database already exists at C:\Users\abhis\Downloads\Documents\Learner Engagement Project\cache\lmdb_TestLabels_frame_30
Optuna tuning complete. Total successful trials: 10
Best trial parameters: {'num_frames': 30, 'batch_size': 4, 'lr': 0.00046142041717863776, 'epochs': 3, 'hidden_size': 64, 'num_lstm_layers': 2}

--- Skipping Final Training (Checkpoint Exists) ---
Using model from: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_eff_checkpoint.pth
Evaluating: 100%|██████████| 410/410 [00:04<00:00, 99.67it/s] 
Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.04      0.04      0.04        81
           2       0.49      0.47      0.48       849
           3       0.39      0.41      0.40       704

    accuracy                           0.42      1638
   macro avg       0.23      0.23      0.23      1638
weighted avg       0.43      0.42      0.42      1638

Confusion Matrix:
[[  0   1   1   2]
 [  2   3  28  48]
 [  2  53 402 392]
 [  4  24 388 288]]
Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.47      0.48      0.47       747
           1       0.35      0.35      0.35       519
           2       0.19      0.19      0.19       335
           3       0.03      0.03      0.03        37

    accuracy                           0.37      1638
   macro avg       0.26      0.26      0.26      1638
weighted avg       0.36      0.37      0.37      1638

Confusion Matrix:
[[355 223 155  14]
 [227 181  96  15]
 [167 103  63   2]
 [  6  17  13   1]]
Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      1135
           1       0.30      0.30      0.30       368
           2       0.25      0.24      0.24       116
           3       0.00      0.00      0.00        19

    accuracy                           0.59      1638
   macro avg       0.32      0.32      0.32      1638
weighted avg       0.59      0.59      0.59      1638

Confusion Matrix:
[[827 240  56  12]
 [230 112  23   3]
 [ 64  21  28   3]
 [  9   3   7   0]]
Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1279
           1       0.29      0.29      0.29       280
           2       0.05      0.05      0.05        56
           3       0.06      0.04      0.05        23

    accuracy                           0.70      1638
   macro avg       0.31      0.30      0.30      1638
weighted avg       0.70      0.70      0.70      1638

Confusion Matrix:
[[1055  161   51   12]
 [ 186   82    7    5]
 [  31   22    3    0]
 [   5   13    4    1]]

--- Evaluation Complete ---


12. EfficientNetB3_LSTM_300.ipynb

[I 2025-03-25 06:16:38,103] Using an existing study with name 'efficientnetb3_lstm_study_300' instead of creating a new one.
Optuna tuning complete. Total successful trials: 10
Best trial parameters: {'num_frames': 30, 'batch_size': 4, 'lr': 0.00040477702853598276, 'epochs': 3, 'hidden_size': 128, 'num_lstm_layers': 1}

--- Skipping Final Training (Checkpoint Exists) ---
Using model from: C:\Users\abhis\Downloads\Documents\Learner Engagement Project\models\final_model_eff_checkpoint_300.pth
Evaluating: 100%|██████████| 410/410 [00:03<00:00, 126.03it/s]
Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.12      0.25      0.17         4
           1       0.05      0.05      0.05        81
           2       0.53      0.51      0.52       849
           3       0.43      0.45      0.44       704

    accuracy                           0.46      1638
   macro avg       0.28      0.31      0.29      1638
weighted avg       0.46      0.46      0.46      1638

Confusion Matrix:
[[  1   0   1   2]
 [  2   4  25  50]
 [  4  46 435 364]
 [  1  31 358 314]]
Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.50      0.51      0.50       747
           1       0.37      0.37      0.37       519
           2       0.20      0.20      0.20       335
           3       0.00      0.00      0.00        37

    accuracy                           0.39      1638
   macro avg       0.27      0.27      0.27      1638
weighted avg       0.39      0.39      0.39      1638

Confusion Matrix:
[[378 190 160  19]
 [224 192  92  11]
 [142 125  66   2]
 [ 11  17   9   0]]
Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.74      0.74      0.74      1135
           1       0.27      0.27      0.27       368
           2       0.20      0.20      0.20       116
           3       0.00      0.00      0.00        19

    accuracy                           0.59      1638
   macro avg       0.30      0.30      0.30      1638
weighted avg       0.59      0.59      0.59      1638

Confusion Matrix:
[[837 227  58  13]
 [233 101  29   5]
 [ 48  45  23   0]
 [ 12   3   4   0]]
Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1279
           1       0.26      0.26      0.26       280
           2       0.05      0.05      0.05        56
           3       0.00      0.00      0.00        23

    accuracy                           0.68      1638
   macro avg       0.28      0.28      0.28      1638
weighted avg       0.68      0.68      0.68      1638

Confusion Matrix:
[[1040  178   44   17]
 [ 190   73   16    1]
 [  31   22    3    0]
 [  16    5    2    0]]

--- Evaluation Complete ---

13. tuning_effv2l_bilstm_flow_ema.ipynb

Classification report for Engagement:
              precision    recall  f1-score   support

           0       0.00      0.50      0.00         4
           1       0.00      0.00      0.00        81
           2       0.66      0.10      0.17       849
           3       0.41      0.42      0.41       704

    accuracy                           0.23      1638
   macro avg       0.27      0.25      0.15      1638
weighted avg       0.52      0.23      0.26      1638

Confusion Matrix:
[[  2   0   2   0]
 [ 41   0   6  34]
 [383   0  81 385]
 [377   0  34 293]]

Classification report for Boredom:
              precision    recall  f1-score   support

           0       0.46      0.68      0.55       747
           1       0.29      0.11      0.16       519
           2       0.22      0.19      0.20       335
           3       0.03      0.03      0.03        37

    accuracy                           0.39      1638
   macro avg       0.25      0.25      0.24      1638
weighted avg       0.35      0.39      0.34      1638

Confusion Matrix:
[[511  76 137  23]
 [366  58  90   5]
 [213  55  64   3]
 [ 24   8   4   1]]


Classification report for Confusion:
              precision    recall  f1-score   support

           0       0.67      0.75      0.71      1135
           1       0.18      0.12      0.15       368
           2       0.05      0.04      0.05       116
           3       0.00      0.00      0.00        19

    accuracy                           0.55      1638
   macro avg       0.23      0.23      0.23      1638
weighted avg       0.51      0.55      0.53      1638

Confusion Matrix:
[[851 195  73  16]
 [301  46  21   0]
 [ 92  19   5   0]
 [ 18   1   0   0]]

Classification report for Frustration:
              precision    recall  f1-score   support

           0       0.77      0.81      0.79      1279
           1       0.12      0.09      0.11       280
           2       0.06      0.05      0.06        56
           3       0.00      0.00      0.00        23

    accuracy                           0.65      1638
   macro avg       0.24      0.24      0.24      1638
weighted avg       0.62      0.65      0.64      1638

Confusion Matrix:
[[1041  183   40   15]
 [ 248   26    5    1]
 [  49    4    3    0]
 [  22    0    1    0]]










